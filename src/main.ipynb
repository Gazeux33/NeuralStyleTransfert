{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-17T11:15:05.737116Z",
     "start_time": "2024-05-17T11:15:04.104445Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "from vgg19 import Vgg19\n",
    "import config\n",
    "\n",
    "import NST\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T11:15:10.561703Z",
     "start_time": "2024-05-17T11:15:10.558543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "ff6ec5c7f6bf9436",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T11:15:17.464277Z",
     "start_time": "2024-05-17T11:15:17.411714Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # load and reshape the content image\n",
    "content_img = utils.load_image(os.path.join(config.CONTENT_DIR,config.content_name),config.HEIGHT)\n",
    "# load and reshape the style image\n",
    "style_img = utils.load_image(os.path.join(config.STYLE_DIR,config.style_name),config.HEIGHT) \n",
    "content_img.shape,style_img.shape"
   ],
   "id": "7a00f6decb9feb89",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 602, 3), (400, 480, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T11:15:21.204264Z",
     "start_time": "2024-05-17T11:15:20.314138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# use the pretrained model VGG19\n",
    "model = Vgg19() "
   ],
   "id": "2a39260d2ef7dd42",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T11:15:23.938024Z",
     "start_time": "2024-05-17T11:15:23.910530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# transform the content image into tensor and more \n",
    "content_transformed = NST.transform_image(content_img,device) \n",
    "# transform the style image into tensor and more\n",
    "style_transformed = NST.transform_image(style_img,device) \n",
    "content_transformed.shape,style_transformed.shape"
   ],
   "id": "eb23087f0ce444e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 400, 602]), torch.Size([1, 3, 400, 480]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T11:15:26.770150Z",
     "start_time": "2024-05-17T11:15:26.766483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "init_img = content_transformed # define the init image (it can be random noise, content or style)\n",
    "optimizing_img = Variable(init_img,requires_grad=True) # define the variables who will be optimize to reduce loss (we optimize image's pixels)"
   ],
   "id": "5b59771844bd0838",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-17T11:15:29.453234Z",
     "start_time": "2024-05-17T11:15:28.616842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "content_set_features_map = model(content_transformed)# get the set of features map of content image \n",
    "style_set_features_map = model(style_transformed)# get the set of features map of style image \n",
    "len(content_set_features_map),len(style_set_features_map)"
   ],
   "id": "a8a36814dfb92ed6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ae5689e74633f8f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:33:49.213689Z",
     "start_time": "2024-05-16T19:33:49.211506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"INITIAL: content shape:{content_transformed.shape} | style shape:{style_transformed.shape}\")\n",
    "for i in range(len(content_set_features_map)):\n",
    "    print(f\"{i}:content shape:{content_set_features_map[i].shape} | style shape:{style_set_features_map[i].shape}\")"
   ],
   "id": "b4f28e082b070c2e",
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:33:49.216936Z",
     "start_time": "2024-05-16T19:33:49.214264Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer = torch.optim.LBFGS([optimizing_img],max_iter=config.ITERATION,line_search_fn=\"strong_wolfe\")",
   "id": "2ed25acd22878a71",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:33:49.231653Z",
     "start_time": "2024-05-16T19:33:49.217573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_content = content_set_features_map[model.content_layers]\n",
    "target_style = [NST.gram_matrix(x) for i,x in enumerate(style_set_features_map) if i in model.style_layers]"
   ],
   "id": "b9cdb05993233d3",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ec108853484694f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:33:49.235004Z",
     "start_time": "2024-05-16T19:33:49.232315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def loss_fn(model, target_content, target_style, current_img):\n",
    "    current_img_set_features_map = model(current_img)\n",
    "\n",
    "    # Content Loss\n",
    "    content_loss_fn = torch.nn.MSELoss(reduction=\"mean\")\n",
    "    content_loss = content_loss_fn(target_content, current_img_set_features_map[4])\n",
    "\n",
    "    # Style Loss\n",
    "    style_loss_fn = torch.nn.MSELoss(reduction=\"sum\")\n",
    "    style_loss = 0.0\n",
    "    current_style_representation = [NST.gram_matrix(x) for i, x in enumerate(current_img_set_features_map) if i != 4]\n",
    "    for gram_target, gram_current in zip(target_style, current_style_representation):\n",
    "        style_loss += style_loss_fn(gram_target, gram_current)\n",
    "    style_loss /= len(current_style_representation)\n",
    "    \n",
    "    #total variation loss\n",
    "    tv_loss = utils.total_variation(optimizing_img)\n",
    "\n",
    "    # Total loss\n",
    "    total_loss = (content_loss * config.CONTENT_WEIGHT) + (style_loss*config.STYLE_WEIGHT) + (tv_loss*config.TV_WEIGHT)\n",
    "    return total_loss,content_loss,style_loss,tv_loss\n",
    "    "
   ],
   "id": "f31675d441ce9d18",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "        ",
   "id": "404ae7497b1e215f",
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:56:09.630280Z",
     "start_time": "2024-05-16T19:33:49.236746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "counter = 0\n",
    "\n",
    "def optimize_step():\n",
    "    global counter\n",
    "    optimizer.zero_grad()\n",
    "    total_loss,content_loss,style_loss,tv_loss = loss_fn(model, target_content, target_style, optimizing_img)\n",
    "    total_loss.backward()\n",
    "    print(f\"iteration:{counter} total_loss:{total_loss.item()} content_loss:{content_loss.item()} style_loss:{style_loss.item()} tv_loss:{tv_loss.item()}\")\n",
    "    counter+=1\n",
    "    return total_loss\n",
    "\n",
    "# Perform optimization\n",
    "optimizer.step(optimize_step)\n",
    "    "
   ],
   "id": "211e75615b32d1f8",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:56:09.655788Z",
     "start_time": "2024-05-16T19:56:09.634902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "final_img = optimizing_img.squeeze().permute(1,2,0).to('cpu').detach().numpy()\n",
    "final_img = utils.get_uint8_range(final_img)\n",
    "final_img /=255\n",
    "final_img.shape"
   ],
   "id": "ab1b99d775b9f556",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:56:09.879996Z",
     "start_time": "2024-05-16T19:56:09.656922Z"
    }
   },
   "cell_type": "code",
   "source": "utils.display_image(final_img)",
   "id": "1348c2f728f054e9",
   "execution_count": 34,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:56:09.970186Z",
     "start_time": "2024-05-16T19:56:09.880684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result_name = utils.get_name(config.content_name,config.style_name)\n",
    "result_img_path = os.path.join(config.RESULT_DIR, f\"{result_name}.png\")\n",
    "plt.imsave(result_img_path, final_img)"
   ],
   "id": "ca7b8724a27e4d83",
   "execution_count": 35,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-16T19:56:09.972147Z",
     "start_time": "2024-05-16T19:56:09.970740Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7012506d9e35aedb",
   "execution_count": 35,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
