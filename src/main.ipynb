{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-15T20:34:27.587158Z",
     "start_time": "2024-05-15T20:34:25.637096Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "from vgg19 import Vgg19\n",
    "import config\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T20:34:27.589569Z",
     "start_time": "2024-05-15T20:34:27.588092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "id": "ff6ec5c7f6bf9436",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T20:34:27.755130Z",
     "start_time": "2024-05-15T20:34:27.590109Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # load and reshape the content image\n",
    "content_img = utils.load_image(os.path.join(config.CONTENT_DIR,config.content_name),config.HEIGHT)\n",
    "# load and reshape the style image\n",
    "style_img = utils.load_image(os.path.join(config.STYLE_DIR,config.style_name),config.HEIGHT) \n",
    "content_img.shape,style_img.shape"
   ],
   "id": "7a00f6decb9feb89",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((400, 653, 3), (400, 505, 3))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T20:34:28.686289Z",
     "start_time": "2024-05-15T20:34:27.757370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# use the pretrained model VGG19\n",
    "model = Vgg19() "
   ],
   "id": "2a39260d2ef7dd42",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T20:34:28.696408Z",
     "start_time": "2024-05-15T20:34:28.687529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# transform the content image into tensor and more \n",
    "content_transformed = utils.transform_image(content_img,device) \n",
    "# transform the style image into tensor and more\n",
    "style_transformed = utils.transform_image(style_img,device) \n",
    "content_transformed.shape,style_transformed.shape"
   ],
   "id": "eb23087f0ce444e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 400, 653]), torch.Size([1, 3, 400, 505]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T20:34:28.698449Z",
     "start_time": "2024-05-15T20:34:28.697014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "init_img = content_transformed # define the init image (it can be random noise, content or style)\n",
    "optimizing_img = Variable(init_img,requires_grad=True) # define the variables who will be optimize to reduce loss (we optimize image's pixels)"
   ],
   "id": "5b59771844bd0838",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T20:34:29.602562Z",
     "start_time": "2024-05-15T20:34:28.698972Z"
    }
   },
   "cell_type": "code",
   "source": [
    "content_set_features_map = model(content_transformed)# get the set of features map of content image \n",
    "style_set_features_map = model(style_transformed)# get the set of features map of style image \n",
    "len(content_set_features_map),len(style_set_features_map)"
   ],
   "id": "a8a36814dfb92ed6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T20:34:29.606648Z",
     "start_time": "2024-05-15T20:34:29.603303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"INITIAL: content shape:{content_transformed.shape} | style shape:{style_transformed.shape}\")\n",
    "for i in range(len(content_set_features_map)):\n",
    "    print(f\"{i}:content shape:{content_set_features_map[i].shape} | style shape:{style_set_features_map[i].shape}\")"
   ],
   "id": "b4f28e082b070c2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL: content shape:torch.Size([1, 3, 400, 653]) | style shape:torch.Size([1, 3, 400, 505])\n",
      "0:content shape:torch.Size([1, 64, 400, 653]) | style shape:torch.Size([1, 64, 400, 505])\n",
      "1:content shape:torch.Size([1, 128, 200, 326]) | style shape:torch.Size([1, 128, 200, 252])\n",
      "2:content shape:torch.Size([1, 256, 100, 163]) | style shape:torch.Size([1, 256, 100, 126])\n",
      "3:content shape:torch.Size([1, 512, 50, 81]) | style shape:torch.Size([1, 512, 50, 63])\n",
      "4:content shape:torch.Size([1, 512, 50, 81]) | style shape:torch.Size([1, 512, 50, 63])\n",
      "5:content shape:torch.Size([1, 512, 25, 40]) | style shape:torch.Size([1, 512, 25, 31])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T20:34:29.609791Z",
     "start_time": "2024-05-15T20:34:29.607203Z"
    }
   },
   "cell_type": "code",
   "source": "optimizer = torch.optim.LBFGS([optimizing_img],max_iter=config.ITERATION,line_search_fn=\"strong_wolfe\")",
   "id": "2ed25acd22878a71",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T20:34:29.624029Z",
     "start_time": "2024-05-15T20:34:29.611462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_content = content_set_features_map[config.target_content_layer]\n",
    "target_style = [utils.gram_matrix(x) for i,x in enumerate(style_set_features_map) if i in config.target_style_layer]"
   ],
   "id": "b9cdb05993233d3",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ec108853484694f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T20:34:29.629021Z",
     "start_time": "2024-05-15T20:34:29.626588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def loss_fn(model, target_content, target_style, current_img):\n",
    "    current_img_set_features_map = model(current_img)\n",
    "\n",
    "    # Content Loss\n",
    "    content_loss_fn = torch.nn.MSELoss(reduction=\"mean\")\n",
    "    content_loss = content_loss_fn(target_content, current_img_set_features_map[4])\n",
    "\n",
    "    # Style Loss\n",
    "    style_loss_fn = torch.nn.MSELoss(reduction=\"sum\")\n",
    "    style_loss = 0.0\n",
    "    current_style_representation = [utils.gram_matrix(x) for i, x in enumerate(current_img_set_features_map) if i != 4]\n",
    "    for gram_target, gram_current in zip(target_style, current_style_representation):\n",
    "        style_loss += style_loss_fn(gram_target, gram_current)\n",
    "    style_loss /= len(current_style_representation)\n",
    "    \n",
    "    #total variation loss\n",
    "    tv = utils.total_variation(optimizing_img)\n",
    "\n",
    "    # Total loss\n",
    "    total_loss = (content_loss * config.CONTENT_WEIGHT) + (style_loss*config.STYLE_WEIGHT) + (tv*config.TV_WEIGHT)\n",
    "    return total_loss\n",
    "    "
   ],
   "id": "f31675d441ce9d18",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T20:34:29.631291Z",
     "start_time": "2024-05-15T20:34:29.629680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dir_name = f\"{config.content_name}_{config.style_name}\"\n",
    "os.makedirs(dir_name,exist_ok=True)"
   ],
   "id": "85f55d5929630588",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-05-15T20:34:29.631771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "counter = 0\n",
    "\n",
    "def optimize_step():\n",
    "    global counter\n",
    "    optimizer.zero_grad()\n",
    "    total_loss = loss_fn(model, target_content, target_style, optimizing_img)\n",
    "    total_loss.backward()\n",
    "    print(f\"iteration:{counter} total_loss:{total_loss.item()}\")\n",
    "    counter+=1\n",
    "    return total_loss\n",
    "\n",
    "# Perform optimization\n",
    "optimizer.step(optimize_step)\n",
    "    "
   ],
   "id": "211e75615b32d1f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration:0 total_loss:1733879791616.0\n",
      "iteration:1 total_loss:1733879660544.0\n",
      "iteration:2 total_loss:1733879398400.0\n",
      "iteration:3 total_loss:1733879398400.0\n",
      "iteration:4 total_loss:1733879398400.0\n",
      "iteration:5 total_loss:1725762633728.0\n",
      "iteration:6 total_loss:1656571691008.0\n",
      "iteration:7 total_loss:976788783104.0\n",
      "iteration:8 total_loss:782896857088.0\n",
      "iteration:9 total_loss:609305559040.0\n",
      "iteration:10 total_loss:509113237504.0\n",
      "iteration:11 total_loss:382903681024.0\n",
      "iteration:12 total_loss:297350627328.0\n",
      "iteration:13 total_loss:271415230464.0\n",
      "iteration:14 total_loss:238151991296.0\n",
      "iteration:15 total_loss:206951301120.0\n",
      "iteration:16 total_loss:171629346816.0\n",
      "iteration:17 total_loss:144363814912.0\n",
      "iteration:18 total_loss:134879436800.0\n",
      "iteration:19 total_loss:124782706688.0\n",
      "iteration:20 total_loss:114936143872.0\n",
      "iteration:21 total_loss:105050587136.0\n",
      "iteration:22 total_loss:94369488896.0\n",
      "iteration:23 total_loss:81126793216.0\n",
      "iteration:24 total_loss:69730656256.0\n",
      "iteration:25 total_loss:69408514048.0\n",
      "iteration:26 total_loss:66150141952.0\n",
      "iteration:27 total_loss:61030465536.0\n",
      "iteration:28 total_loss:53495771136.0\n",
      "iteration:29 total_loss:46678159360.0\n",
      "iteration:30 total_loss:45665161216.0\n",
      "iteration:31 total_loss:44172173312.0\n",
      "iteration:32 total_loss:41165099008.0\n",
      "iteration:33 total_loss:36454952960.0\n",
      "iteration:34 total_loss:32637814784.0\n",
      "iteration:35 total_loss:27988199424.0\n",
      "iteration:36 total_loss:28502245376.0\n",
      "iteration:37 total_loss:27038500864.0\n",
      "iteration:38 total_loss:25432825856.0\n",
      "iteration:39 total_loss:23140030464.0\n",
      "iteration:40 total_loss:21134430208.0\n",
      "iteration:41 total_loss:20564234240.0\n",
      "iteration:42 total_loss:20065038336.0\n",
      "iteration:43 total_loss:19512827904.0\n",
      "iteration:44 total_loss:18690568192.0\n",
      "iteration:45 total_loss:17946779648.0\n",
      "iteration:46 total_loss:17155288064.0\n",
      "iteration:47 total_loss:15751739392.0\n",
      "iteration:48 total_loss:14527776768.0\n",
      "iteration:49 total_loss:14673447936.0\n",
      "iteration:50 total_loss:14169234432.0\n",
      "iteration:51 total_loss:13812074496.0\n",
      "iteration:52 total_loss:12715677696.0\n",
      "iteration:53 total_loss:12175805440.0\n",
      "iteration:54 total_loss:11653630976.0\n",
      "iteration:55 total_loss:11363802112.0\n",
      "iteration:56 total_loss:11000715264.0\n",
      "iteration:57 total_loss:10533525504.0\n",
      "iteration:58 total_loss:10019693568.0\n",
      "iteration:59 total_loss:9497690112.0\n",
      "iteration:60 total_loss:9113439232.0\n",
      "iteration:61 total_loss:8754802688.0\n",
      "iteration:62 total_loss:8916661248.0\n",
      "iteration:63 total_loss:8656821248.0\n",
      "iteration:64 total_loss:8397106688.0\n",
      "iteration:65 total_loss:8030198272.0\n",
      "iteration:66 total_loss:7698878464.0\n",
      "iteration:67 total_loss:7543185920.0\n",
      "iteration:68 total_loss:7316666368.0\n",
      "iteration:69 total_loss:7138203136.0\n",
      "iteration:70 total_loss:6846177792.0\n",
      "iteration:71 total_loss:6553520640.0\n",
      "iteration:72 total_loss:6367451136.0\n",
      "iteration:73 total_loss:6173454336.0\n",
      "iteration:74 total_loss:6143569920.0\n",
      "iteration:75 total_loss:5943860736.0\n",
      "iteration:76 total_loss:5876423680.0\n",
      "iteration:77 total_loss:5736090112.0\n",
      "iteration:78 total_loss:5580138496.0\n",
      "iteration:79 total_loss:5345926144.0\n",
      "iteration:80 total_loss:5151089664.0\n",
      "iteration:81 total_loss:4996051456.0\n",
      "iteration:82 total_loss:4996472320.0\n",
      "iteration:83 total_loss:4950577152.0\n",
      "iteration:84 total_loss:4854584832.0\n",
      "iteration:85 total_loss:4757721600.0\n",
      "iteration:86 total_loss:4555245568.0\n",
      "iteration:87 total_loss:4434341888.0\n",
      "iteration:88 total_loss:4307796992.0\n",
      "iteration:89 total_loss:4223027968.0\n",
      "iteration:90 total_loss:4164538624.0\n",
      "iteration:91 total_loss:4086652928.0\n",
      "iteration:92 total_loss:4019680768.0\n",
      "iteration:93 total_loss:3949007616.0\n",
      "iteration:94 total_loss:3821030144.0\n",
      "iteration:95 total_loss:3708823296.0\n",
      "iteration:96 total_loss:3623429888.0\n",
      "iteration:97 total_loss:3582148608.0\n",
      "iteration:98 total_loss:3529563136.0\n",
      "iteration:99 total_loss:3476481536.0\n",
      "iteration:100 total_loss:3384351232.0\n",
      "iteration:101 total_loss:3283004928.0\n",
      "iteration:102 total_loss:3214776320.0\n",
      "iteration:103 total_loss:3144660224.0\n",
      "iteration:104 total_loss:3119849216.0\n",
      "iteration:105 total_loss:3063317248.0\n",
      "iteration:106 total_loss:3028633088.0\n",
      "iteration:107 total_loss:2980367616.0\n",
      "iteration:108 total_loss:2904186624.0\n",
      "iteration:109 total_loss:2818666496.0\n",
      "iteration:110 total_loss:2817827328.0\n",
      "iteration:111 total_loss:2786832640.0\n",
      "iteration:112 total_loss:2737914880.0\n",
      "iteration:113 total_loss:2687557120.0\n",
      "iteration:114 total_loss:2628265472.0\n",
      "iteration:115 total_loss:2584755712.0\n",
      "iteration:116 total_loss:2548489216.0\n",
      "iteration:117 total_loss:2507728384.0\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "final_img = optimizing_img.squeeze().permute(1,2,0).to('cpu').detach().numpy()\n",
    "final_img = utils.get_uint8_range(final_img)\n",
    "final_img /=255\n",
    "final_img.shape"
   ],
   "id": "ab1b99d775b9f556",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "utils.display_image(final_img)",
   "id": "1348c2f728f054e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "result_name = utils.get_name(config.content_name,config.style_name)\n",
    "result_img_path = os.path.join(config.RESULT_DIR, f\"{result_name}.png\")\n",
    "plt.imsave(result_img_path, final_img)"
   ],
   "id": "ca7b8724a27e4d83",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
